
@article{gelman_inference_1992,
	title = {Inference from {Iterative} {Simulation} {Using} {Multiple} {Sequences}},
	volume = {7},
	issn = {0883-4237, 2168-8745},
	url = {http://projecteuclid.org/euclid.ss/1177011136},
	doi = {10.1214/ss/1177011136},
	abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
	language = {EN},
	number = {4},
	urldate = {2016-06-16},
	journal = {Statistical Science},
	author = {Gelman, Andrew and Rubin, Donald B.},
	month = nov,
	year = {1992},
	keywords = {Bayesian inference, convergence of stochastic processes, ECM, EM, Gibbs sampler, importance sampling, Metropolis algorithm, multiple imputation, random-effects model, SIR},
	pages = {457--472},
	file = {Snapshot:/Users/dskelly/Library/Application Support/Zotero/Profiles/xcw191qw.default/zotero/storage/PCG72SQN/1177011136.html:text/html}
}

@inproceedings{geweke_evaluating_1992,
	title = {Evaluating the {Accuracy} of {Sampling}-{Based} {Approaches} to the {Calculation} of {Posterior} {Moments}},
	abstract = {Data augmentation and Gibbs sampling are two closely related, sampling-based approaches to the calculation of posterior moments. The fact that each produces a sample whose constituents are neither independent nor identically distributed complicates the assessment of convergence and numerical accuracy of the approximations to the expected value of functions of interest under the posterior. In this paper methods from spectral analysis are used to evaluate numerical accuracy formally and construct diagnostics for convergence. These methods are illustrated in the normal linear model with informative priors, and in the Tobit-censored regression model.},
	booktitle = {{IN} {BAYESIAN} {STATISTICS}},
	publisher = {University Press},
	author = {Geweke, John},
	year = {1992},
	pages = {169--193},
	file = {Citeseer - Full Text PDF:/Users/dskelly/Library/Application Support/Zotero/Profiles/xcw191qw.default/zotero/storage/CDI5GDKH/Geweke - 1992 - Evaluating the Accuracy of Sampling-Based Approach.pdf:application/pdf;Citeseer - Snapshot:/Users/dskelly/Library/Application Support/Zotero/Profiles/xcw191qw.default/zotero/storage/MCSVEWIU/summary.html:text/html}
}

@article{heidelberger_simulation_1983,
	title = {Simulation {Run} {Length} {Control} in the {Presence} of an {Initial} {Transient}},
	volume = {31},
	issn = {0030-364X},
	url = {http://www.jstor.org/stable/170841},
	abstract = {This paper studies the estimation of the steady state mean of an output sequence from a discrete event simulation. It considers the problem of the automatic generation of a confidence interval of prespecified width when there is an initial transient present. It explores a procedure based on Schruben's Brownian bridge model for the detection of nonstationarity and a spectral method for estimating the variance of the sample mean. The procedure is evaluated empirically for a variety of output sequences. The performance measures considered are bias, confidence interval coverage, mean confidence interval width, mean run length, and mean amount of deleted data. If the output sequence contains a strong transient, then inclusion of a test for stationarity in the run length control procedure results in point estimates with lower bias, narrower confidence intervals, and shorter run lengths than when no check for stationarity is performed. If the output sequence contains no initial transient, then the performance measures of the procedure with a stationarity test are only slightly degraded from those of the procedure without such a test. If the run length is short relative to the extent of the initial transient, the stationarity tests may not be powerful enough to detect the transient, resulting in a procedure with unreliable point and interval estimates.},
	number = {6},
	urldate = {2016-06-16},
	journal = {Operations Research},
	author = {Heidelberger, Philip and Welch, Peter D.},
	year = {1983},
	pages = {1109--1144}
}